import os
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import torchaudio
from transformers import Wav2Vec2Processor, Wav2Vec2Model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from tqdm import tqdm

# ================= ğŸ”§ çµ±ä¸€åƒæ•¸è¨­å®š =================
AUDIO_ROOT = "/export/fs05/hyeh10/depression/daic_5utt_full/merged_5"
CSV_A_TEST = "experiment_sisman_scientific/scenario_A_screening/test.csv"
CSV_B_TRAIN = "experiment_sisman_scientific/scenario_B_monitoring/train.csv"
CSV_B_TEST = "experiment_sisman_scientific/scenario_B_monitoring/test.csv"

# æ¨¡å‹è·¯å¾‘
PATH_BASELINE = "best_model_frozen_weighted.pth"
PATH_DANN_A = "best_dann_model.pth"
PATH_DANN_B = "dann_model_scenario_B_final.pth"

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ================= ğŸ§  æ¨¡å‹çµæ§‹å®šç¾© =================
class DANN_Encoder(nn.Module):
    def __init__(self, is_dann=True):
        super().__init__()
        self.w2v = Wav2Vec2Model.from_pretrained("facebook/wav2vec2-base")
        self.is_dann = is_dann
        if is_dann:
            self.shared_layer = nn.Sequential(
                nn.Linear(768, 128),
                nn.BatchNorm1d(128),
                nn.ReLU()
            )
    def forward(self, x):
        feat = self.w2v(x).last_hidden_state.mean(dim=1)
        if self.is_dann:
            feat = self.shared_layer(feat)
        return feat

# ================= ğŸ“‚ ç‰¹å¾µæå–å‡½æ•¸ =================
def get_features(model, csv_path, processor):
    df = pd.read_csv(csv_path)
    # è§£æ Speaker ID
    df['spk'] = df['path'].apply(lambda x: str(x).split('/')[-1].split('_')[0])
    feats, spks = [], []
    model.eval()
    with torch.no_grad():
        for _, row in tqdm(df.iterrows(), total=len(df), desc=f"Reading {os.path.basename(csv_path)}", leave=False):
            wav_path = os.path.join(AUDIO_ROOT, row['path'])
            try:
                s, sr = torchaudio.load(wav_path)
                if sr != 16000: s = torchaudio.transforms.Resample(sr, 16000)(s)
                # é™åˆ¶é•·åº¦ä»¥å… OOM
                if s.shape[1] > 16000*8: s = s[:, :16000*8]
                inp = processor(s.squeeze().numpy(), sampling_rate=16000, return_tensors="pt").input_values.to(DEVICE)
                emb = model(inp).cpu().numpy().squeeze()
                feats.append(emb)
                spks.append(row['spk'])
            except: pass
    return np.array(feats), np.array(spks)

# ================= ğŸš€ ä¸»ç¨‹åº =================
if __name__ == "__main__":
    processor = Wav2Vec2Processor.from_pretrained("facebook/wav2vec2-base")
    results = {}

    exp_configs = [
        {"name": "Baseline_A", "path": PATH_BASELINE, "is_dann": False, "csv_tr": CSV_A_TEST, "csv_te": CSV_A_TEST, "mode": "cv"},
        {"name": "DANN_A", "path": PATH_DANN_A, "is_dann": True, "csv_tr": CSV_A_TEST, "csv_te": CSV_A_TEST, "mode": "cv"},
        {"name": "Baseline_B", "path": PATH_BASELINE, "is_dann": False, "csv_tr": CSV_B_TRAIN, "csv_te": CSV_B_TEST, "mode": "split"},
        {"name": "DANN_B", "path": PATH_DANN_B, "is_dann": True, "csv_tr": CSV_B_TRAIN, "csv_te": CSV_B_TEST, "mode": "split"},
    ]

    for config in exp_configs:
        print(f"\nğŸ” æ­£åœ¨é‹è¡Œ: {config['name']}")
        model = DANN_Encoder(is_dann=config['is_dann']).to(DEVICE)
        
        # --- ğŸ”¥ é—œéµä¿®æ­£ï¼šæ™ºæ…§æ¬Šé‡è¼‰å…¥é‚è¼¯ ---
        if os.path.exists(config['path']):
            raw_state_dict = torch.load(config['path'], map_location=DEVICE)
            new_state_dict = {}
            
            for k, v in raw_state_dict.items():
                # ä¿®æ­£ 1: è™•ç†æ²’æœ‰å‰ç¶´çš„ shared_layer (å¦‚ 0.weight -> shared_layer.0.weight)
                if config['is_dann'] and (k.startswith("0.") or k.startswith("1.") or k.startswith("2.")):
                    new_key = "shared_layer." + k
                    new_state_dict[new_key] = v
                # ä¿®æ­£ 2: ä¿ç•™å·²ç¶“æ­£ç¢ºçš„ shared_layer
                elif "shared_layer" in k:
                    new_state_dict[k] = v
                # ä¿®æ­£ 3: ä¿ç•™ Wav2Vec2 ç›¸é—œæ¬Šé‡ (å¦‚æœæœ‰å¾®èª¿é)
                else:
                    new_state_dict[k] = v
            
            # è¼‰å…¥æ¬Šé‡ (strict=False æ˜¯ç‚ºäº†å¿½ç•¥ discriminator ç­‰å¤šé¤˜çš„å±¤ï¼Œä½†æˆ‘å€‘å·²ç¢ºä¿ shared_layer å°é½Š)
            load_res = model.load_state_dict(new_state_dict, strict=False)
            
            # ç°¡å–®é©—è­‰
            if config['is_dann']:
                missing = [k for k in load_res.missing_keys if "shared_layer" in k]
                if missing:
                    print(f"âš ï¸ åš´é‡è­¦å‘Š: {config['name']} çš„ shared_layer ä»æœ‰ç¼ºå¤±ï¼{missing}")
                else:
                    print(f"âœ… {config['name']} æ¬Šé‡è¼‰å…¥æˆåŠŸ (Shared Layer å·²å°é½Š)")
        else:
            print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {config['path']}ï¼Œå°‡ä½¿ç”¨éš¨æ©Ÿåˆå§‹æ¬Šé‡ï¼")

        # --- é–‹å§‹ç‰¹å¾µæå–èˆ‡è©•ä¼° ---
        if config['mode'] == "cv":
            # Scenario A: 5-Fold Cross Validation
            X, y = get_features(model, config['csv_te'], processor)
            from sklearn.model_selection import StratifiedKFold
            skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
            accs = []
            # ç‚ºäº†é¿å…æŸäº› Fold æ²’æœ‰æ¨£æœ¬ï¼ŒåŠ å€‹ç°¡å–®çš„éŒ¯èª¤è™•ç†
            try:
                for tr_idx, te_idx in skf.split(X, y):
                    clf = LogisticRegression(max_iter=1000, class_weight='balanced')
                    clf.fit(X[tr_idx], y[tr_idx])
                    accs.append(accuracy_score(y[te_idx], clf.predict(X[te_idx])))
                results[config['name']] = np.mean(accs)
            except Exception as e:
                print(f"âš ï¸ CV åŸ·è¡ŒéŒ¯èª¤ (å¯èƒ½æ˜¯æ¨£æœ¬å¤ªå°‘): {e}")
                results[config['name']] = 0.0
        else:
            # Scenario B: Train/Test Split
            X_tr, y_tr = get_features(model, config['csv_tr'], processor)
            X_te, y_te = get_features(model, config['csv_te'], processor)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„è¨“ç·´æ•¸æ“š
            if len(set(y_tr)) > 1:
                clf = LogisticRegression(max_iter=1000, class_weight='balanced')
                clf.fit(X_tr, y_tr)
                # ç¢ºä¿æ¸¬è©¦é›†è£¡çš„ Speaker åœ¨è¨“ç·´é›†è£¡è¦‹é (é‡å° Probe ä»»å‹™)
                # ä½†é€™è£¡æ˜¯æ¸¬æ´©æ¼ï¼Œæ‰€ä»¥ç›´æ¥æ¸¬ä¹Ÿç„¡å¦¨ï¼Œæ²’çœ‹éçš„å°±çŒœéŒ¯ï¼Œç¬¦åˆé‚è¼¯
                results[config['name']] = accuracy_score(y_te, clf.predict(X_te))
            else:
                print("âš ï¸ è¨“ç·´é›†åªæœ‰ä¸€é¡ Speakerï¼Œç„¡æ³•è¨“ç·´ Probeã€‚")
                results[config['name']] = 0.0

    # ğŸ“Š è¼¸å‡ºæœ€çµ‚çµæœ
    print("\n" + "="*50)
    print("ğŸ† æœ€çµ‚çµ±ä¸€æ¨™æº–çµæœ (Speaker Accuracy)")
    print("="*50)
    for name, acc in results.items():
        print(f"{name}: {acc*100:.2f}%")