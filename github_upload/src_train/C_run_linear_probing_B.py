import os
import argparse
import yaml
import torch
import numpy as np
from datasets import load_from_disk
from transformers import Wav2Vec2Model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from tqdm import tqdm

def run_linear_probing(config_path):
    with open(config_path) as f:
        config = yaml.load(f, Loader=yaml.FullLoader)

    features_path = os.path.join(config['output_dir'], 'features')
    train_dir = os.path.join(features_path, "train_dataset")
    eval_dir = os.path.join(features_path, "eval_dataset")

    try:
        train_dataset = load_from_disk(train_dir)
        eval_dataset = load_from_disk(eval_dir)
    except Exception as e:
        print(f"âŒ è®€å–è³‡æ–™é›†å¤±æ•—: {e}")
        return

    # 1. å–šé†’ Wav2Vec2 æ¨¡å‹ä¾†ç•¶ã€Œç‰¹å¾µæŠ½å–å™¨ã€
    print("ğŸ§  æ­£åœ¨è¼‰å…¥ Wav2Vec2 æ¨¡å‹æå–æ·±å±¤ç‰¹å¾µ (Embeddings)...")
    
    # è‡ªå‹•åµæ¸¬æ˜¯å¦æœ‰ GPU å¯ä»¥åŠ é€Ÿ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ é‹ç®—è¨­å‚™: {device}")
    
    model_name = config.get('processor_name_or_path', 'facebook/wav2vec2-base')
    model = Wav2Vec2Model.from_pretrained(model_name).to(device)
    model.eval() # é–å®šæ¨¡å‹ï¼Œä¸æ›´æ–°æ¬Šé‡

    # 2. å®šç¾©æŠ½å–å‡½æ•¸
    def get_embeddings(dataset):
        embeddings = []
        labels = []
        for item in tqdm(dataset, desc="æŠ½å–ç‰¹å¾µä¸­"):
            # å–å‡ºåŸå§‹æ³¢å½¢ï¼Œè½‰æˆ tensor ä¸¦ä¸Ÿåˆ° GPU/CPU
            input_values = torch.tensor(item['input_values']).unsqueeze(0).to(device)
            if input_values.shape[1] == 0: continue
            
            with torch.no_grad(): # çœè¨˜æ†¶é«”å¤§æ³•
                outputs = model(input_values)
                # å–å‡ºæœ€å¾Œä¸€å±¤çš„ç‰¹å¾µï¼Œä¸¦å°æ™‚é–“è»¸åšå¹³å‡ (Global Average Pooling) -> è®Šæˆ 768 ç¶­
                hidden_state = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()
            
            embeddings.append(hidden_state)
            labels.append(item['labels'])
        return np.array(embeddings), np.array(labels)

    # 3. é–‹å§‹æŠ½å–
    print("\nâ³ è½‰æ›ã€è¨“ç·´é›†ã€‘ (é€™éœ€è¦ä¸€é»æ™‚é–“)...")
    X_train, y_train = get_embeddings(train_dataset)
    print("\nâ³ è½‰æ›ã€æ¸¬è©¦é›†ã€‘...")
    X_test, y_test = get_embeddings(eval_dataset)

    print(f"\nâœ… æˆåŠŸç²å¾—æ·±å±¤ç‰¹å¾µï¼é€²å…¥ Linear Probing æ¨¡å‹å½¢ç‹€: X_train={X_train.shape}")
    
    # 4. çœŸæ­£å…¬å¹³çš„å°æ±ºï¼šLogistic Regression (åŸ·è¡Œ 5 æ¬¡)
    TOTAL_RUNS = 5
    all_accs = []
    all_f1s = []

    print(f"\nğŸš€ é–‹å§‹åŸ·è¡Œ Linear Probing ({TOTAL_RUNS} æ¬¡å¯¦é©—)...")
    
    for run_i in range(1, TOTAL_RUNS + 1):
        print(f"\n{'-'*30}")
        print(f"ğŸ¬ Run {run_i} / {TOTAL_RUNS}")
        print(f"{'-'*30}")
        
        # æ¯æ¬¡æ›´æ› random_state ç¢ºä¿åˆå§‹ç‹€æ…‹èˆ‡æ¼”ç®—æ³•éš¨æ©Ÿæ€§ä¸åŒ
        current_seed = 42 + run_i
        
        clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=current_seed)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        
        acc = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='macro') # ä½¿ç”¨ macro F1 å°é½Šä½ çš„å…¶ä»–å¯¦é©—
        
        all_accs.append(acc)
        all_f1s.append(f1)
        
        print(f"Run {run_i} -> Acc: {acc:.4f} | F1: {f1:.4f}")

        # å¦‚æœä½ æƒ³çœ‹ç¬¬ä¸€æ¬¡çš„è©³ç´°å ±å‘Šï¼Œå¯ä»¥è§£é™¤é€™è£¡çš„è¨»è§£
        # if run_i == 1:
        #     print("\nğŸ“Š ç¬¬ä¸€æ¬¡å¯¦é©—çš„è©³ç´°å ±å‘Š:")
        #     print(classification_report(y_test, y_pred, zero_division=0))
        #     print("æ··æ·†çŸ©é™£:\n", confusion_matrix(y_test, y_pred))

    # ==========================================
    # 5. è¼¸å‡ºäº”æ¬¡å¹³å‡èˆ‡æ¨™æº–å·®
    # ==========================================
    print(f"\n{'='*50}")
    print(f"ğŸ† Linear Probing ({TOTAL_RUNS} runs) æœ€çµ‚çµæœçµ±è¨ˆ")
    print(f"{'='*50}")
    
    accs_np = np.array(all_accs)
    f1s_np = np.array(all_f1s)
    
    print(f"ğŸ¯ å¹³å‡ æ†‚é¬±ç—‡ Acc (Dep Acc): {accs_np.mean():.4f} Â± {accs_np.std():.4f}")
    print(f"ğŸ¯ å¹³å‡ æ†‚é¬±ç—‡ F1  (Dep F1) : {f1s_np.mean():.4f} Â± {f1s_np.std():.4f}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', required=True)
    args = parser.parse_args()
    run_linear_probing(args.config)
