import os
import pandas as pd
import numpy as np
import torch
import torchaudio
from tqdm import tqdm
from transformers import Wav2Vec2Processor, Wav2Vec2Model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report

# ==========================================
# 1. è¨­å®šå€ (Config) - å°é½Š Scenario A
# ==========================================

TRAIN_CSV_PATH = "./experiment_sisman_scientific/scenario_B_monitoring/train.csv"
TEST_CSV_PATH = "./experiment_sisman_scientific/scenario_B_monitoring/test.csv"
AUDIO_ROOT = "/export/fs05/hyeh10/depression/daic_5utt_full/merged_5"

MODEL_NAME = "facebook/wav2vec2-base"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
TOTAL_RUNS = 5

print(f"ğŸ–¥ï¸ é‹ç®—è¨­å‚™: {DEVICE}")

# ==========================================
# 2. è³‡æ–™è™•ç†å·¥å…· (ç›´æ¥å¾éŸ³æª”æŠ½å–ï¼Œç¢ºä¿èˆ‡ DANN A å°é½Š)
# ==========================================
def prepare_data_for_probing(csv_path, processor, model):
    df = pd.read_csv(csv_path)
    print(f"ğŸ“‚ æ­£åœ¨è™•ç† {csv_path} (å…± {len(df)} ç­†)...")
    
    features_list = []
    labels_list = []
    label_map = {'dep': 1, '1': 1, 1: 1, 'non': 0, '0': 0, 0: 0}
    
    model.eval()
    with torch.no_grad():
        for _, row in tqdm(df.iterrows(), total=len(df), desc="Extracting Features"):
            wav_path = os.path.join(AUDIO_ROOT, row['path'])
            try:
                waveform, sample_rate = torchaudio.load(wav_path)
                if sample_rate != 16000:
                    waveform = torchaudio.transforms.Resample(sample_rate, 16000)(waveform)
                if waveform.shape[0] > 1: 
                    waveform = torch.mean(waveform, dim=0, keepdim=True)
                
                raw_label = str(row['label']).strip().lower()
                if raw_label not in label_map: continue
                final_label = label_map[raw_label]

                # æå– Wav2Vec2 å‡çµç‰¹å¾µ
                inputs = processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors="pt", padding=True)
                inputs = {k: v.to(DEVICE) for k, v in inputs.items()}
                embeddings = model(**inputs).last_hidden_state.mean(dim=1).cpu()
                
                features_list.append(embeddings)
                labels_list.append(final_label)
                
            except Exception as e:
                print(f"âš ï¸ Error: {wav_path} -> {e}")
                continue

    X = torch.cat(features_list, dim=0).numpy()
    y = np.array(labels_list)
    return X, y

# ==========================================
# 3. ä¸»ç¨‹å¼åŸ·è¡Œ
# ==========================================
if __name__ == "__main__":
    print("ğŸ§  è¼‰å…¥ Wav2Vec2 æ¨¡å‹æå–æ·±å±¤ç‰¹å¾µ...")
    processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)
    w2v_model = Wav2Vec2Model.from_pretrained(MODEL_NAME).to(DEVICE)
    w2v_model.eval() # åš´æ ¼å‡çµ Backboneï¼Œä¸æ›´æ–°æ¬Šé‡

    print("\nâ³ æŠ½å–ã€è¨“ç·´é›†ã€‘ç‰¹å¾µ...")
    X_train, y_train = prepare_data_for_probing(TRAIN_CSV_PATH, processor, w2v_model)
    print("\nâ³ æŠ½å–ã€æ¸¬è©¦é›†ã€‘ç‰¹å¾µ...")
    X_test, y_test = prepare_data_for_probing(TEST_CSV_PATH, processor, w2v_model)

    print(f"\nâœ… ç‰¹å¾µæŠ½å–å®Œç•¢ï¼å½¢ç‹€: X_train={X_train.shape}, X_test={X_test.shape}")

    all_accs = []
    all_f1s = []

    print(f"\nğŸš€ é–‹å§‹åŸ·è¡Œ Linear Probing ({TOTAL_RUNS} æ¬¡å¯¦é©—)...")
    
    # 4. åŸ·è¡Œ 5 æ¬¡è¿´åœˆ
    for run_i in range(1, TOTAL_RUNS + 1):
        print(f"\n{'-'*30}")
        print(f"ğŸ¬ Run {run_i} / {TOTAL_RUNS}")
        print(f"{'-'*30}")
        
        # è¨­å®š Random State ç¢ºä¿æ¯æ¬¡è¨“ç·´çš„éš¨æ©Ÿæ€§ä¸åŒ
        current_seed = 42 + run_i
        
        clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=current_seed)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        
        acc = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='macro')
        
        all_accs.append(acc)
        all_f1s.append(f1)
        
        print(f"Run {run_i} -> Acc: {acc:.4f} | F1: {f1:.4f}")

    # ==========================================
    # 5. è¼¸å‡ºäº”æ¬¡å¹³å‡èˆ‡æ¨™æº–å·®
    # ==========================================
    print(f"\n{'='*50}")
    print(f"ğŸ† Scenario B: Linear Probing ({TOTAL_RUNS} runs) æœ€çµ‚çµæœ")
    print(f"{'='*50}")
    
    accs_np = np.array(all_accs)
    f1s_np = np.array(all_f1s)
    
    print(f"ğŸ¯ å¹³å‡ æ†‚é¬±ç—‡ Acc (Dep Acc): {accs_np.mean():.4f} Â± {accs_np.std():.4f}")
    print(f"ğŸ¯ å¹³å‡ æ†‚é¬±ç—‡ F1  (Dep F1) : {f1s_np.mean():.4f} Â± {f1s_np.std():.4f}")